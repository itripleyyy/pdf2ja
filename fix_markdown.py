#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import sys
import time
import argparse
from pathlib import Path
import re
from typing import List
from collections import deque

from openai import OpenAI


class MarkdownChunker:
    """Markdownãƒ†ã‚­ã‚¹ãƒˆã®ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ã‚’æ‹…å½“ã™ã‚‹ã‚¯ãƒ©ã‚¹"""

    def __init__(self, max_chunk_size: int = 5000, min_chunk_size: int = 500):
        self.max_chunk_size = max_chunk_size
        self.min_chunk_size = min_chunk_size

    def split_markdown(self, markdown_text: str) -> List[str]:
        """Markdownãƒ†ã‚­ã‚¹ãƒˆã‚’ç¿»è¨³ç”¨ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²"""
        if len(markdown_text) <= self.max_chunk_size:
            return [markdown_text]

        # ãƒ˜ãƒƒãƒ€ãƒ¼ã§åˆ†å‰²
        chunks = re.split(r"(?=^#{1,6} .*)", markdown_text, flags=re.MULTILINE)
        chunks = [chunk.strip() for chunk in chunks if chunk.strip()]

        # å°ãƒãƒ£ãƒ³ã‚¯çµåˆ
        chunks = self._merge_small_chunks(chunks)
        return chunks

    def _merge_small_chunks(self, small_chunks: List[str]) -> List[str]:
        if len(small_chunks) <= 1:
            return small_chunks

        chunks: deque[str] = deque(small_chunks)
        merged_chunks = []
        while chunks:
            chunk = chunks.popleft()
            if len(chunk) > self.min_chunk_size:
                merged_chunks.append(chunk)
            elif chunks:
                chunks[0] = chunk + "\n\n" + chunks[0]
            else:
                merged_chunks[-1] += "\n\n" + chunk
        return merged_chunks


REPAIR_SYSTEM_PROMPT = """ã‚ãªãŸã¯ã€PDFãªã©ã‹ã‚‰è‡ªå‹•å¤‰æ›ã•ã‚ŒãŸMarkdownæ–‡æ›¸ã‚’ä¿®å¾©ã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚
å…¥åŠ›ã•ã‚Œã‚‹Markdownã«ã¯ã€è«–æ–‡ã‚„æŠ€è¡“æ›¸ã«å«ã¾ã‚Œã‚‹å†…å®¹ï¼ˆã‚³ãƒ¼ãƒ‰ã€æ•°å¼ã€å›³ã€è¡¨ã€æ®µè½ãªã©ï¼‰ãŒå«ã¾ã‚Œã¾ã™ã€‚
ä»¥ä¸‹ã®æŒ‡ç¤ºã«å¾“ã„ã€Markdownã‚’å†æ§‹ç¯‰ã—ã¦ãã ã•ã„ã€‚

- ã‚³ãƒ¼ãƒ‰ï¼ˆãƒ—ãƒ­ã‚°ãƒ©ãƒ ã€æ“¬ä¼¼ã‚³ãƒ¼ãƒ‰ã€ã‚³ãƒãƒ³ãƒ‰å‡ºåŠ›ï¼‰ã¯é©åˆ‡ãª```ãƒ–ãƒ­ãƒƒã‚¯ã§å›²ã£ã¦ãã ã•ã„ã€‚å¯èƒ½ã§ã‚ã‚Œã°è¨€èªã‚’æŒ‡å®šã—ã¦ãã ã•ã„ï¼ˆä¾‹ï¼š```pythonã€```bashã€```textï¼‰ã€‚
- æ•°å¼ã‚„æ•°å€¤è¡¨ç¾ï¼ˆä¾‹ï¼š$x^2 + y^2 = r^2$ã€\\begin{equation}ãªã©ï¼‰ã¯Markdownã¾ãŸã¯LaTeXå½¢å¼ã§æ­£ã—ãè¡¨ç¤ºã•ã‚Œã‚‹ã‚ˆã†ä¿å…¨ã—ã¦ãã ã•ã„ã€‚
- èª¤ã£ã¦è¦‹å‡ºã—ï¼ˆä¾‹ï¼š`# ã‚³ãƒ¡ãƒ³ãƒˆ`ï¼‰ã¨ã—ã¦å‡¦ç†ã•ã‚ŒãŸè¡Œã¯ã€è¦‹å‡ºã—ã§ã¯ãªãæœ¬æ–‡ã‚„ã‚³ãƒ¡ãƒ³ãƒˆã¨ã—ã¦æ‰±ã£ã¦ãã ã•ã„ã€‚
- ä¸é©åˆ‡ãªæ”¹è¡Œã‚„ç®‡æ¡æ›¸ãã®å´©ã‚Œã€ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆã®èª¤ã‚Šã‚’ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚
- å›³ã‚„è¡¨ï¼ˆãƒ†ãƒ¼ãƒ–ãƒ«ï¼‰ã¨æ€ã‚ã‚Œã‚‹éƒ¨åˆ†ã¯Markdownè¨˜æ³•ã§è¡¨ç¾ã§ãã‚‹ã‚ˆã†ã«æ•´å½¢ã—ã¦ãã ã•ã„ã€‚
- ç”»åƒãƒªãƒ³ã‚¯ï¼ˆ![]()è¨˜æ³•ï¼‰ã¯ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯å†…ã«å«ã‚ãªã„ã§ãã ã•ã„ã€‚ç”»åƒãƒªãƒ³ã‚¯ã®å†…å®¹ï¼ˆãƒ‘ã‚¹ã‚„URLï¼‰ã¯ä¸€åˆ‡å¤‰æ›´ã—ãªã„ã§ãã ã•ã„ã€‚
- å†…å®¹ã‚’è¦ç´„ãƒ»æ”¹å¤‰ã—ãªã„ã§ãã ã•ã„ã€‚**æ§‹é€ ã®ä¿®æ­£ã®ã¿ã«ç•™ã‚ã¦ãã ã•ã„ã€‚**

å‡ºåŠ›ã¯**Markdownå½¢å¼ã®ã¿**ã§è¿”ã—ã¦ãã ã•ã„ã€‚èª¬æ˜ã‚„è£œè¶³ã‚³ãƒ¡ãƒ³ãƒˆã¯ä¸è¦ã§ã™ã€‚"""


class MarkdownFixer:
    """Markdownæ§‹æ–‡ä¿®å¾©ã‚’æ‹…å½“ã™ã‚‹ã‚¯ãƒ©ã‚¹"""

    def __init__(
        self,
        api_key: str = None,
        model: str = "gpt-4.1-mini",
        max_chunk_size: int = 5000,
        min_chunk_size: int = 500,
        verbose: bool = False,
    ):
        self.api_key = api_key or os.environ.get("OPENAI_API_KEY")
        if not self.api_key:
            raise ValueError(
                "OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚--api-key ã‹ç’°å¢ƒå¤‰æ•° OPENAI_API_KEY ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚"
            )

        self.client = OpenAI(api_key=self.api_key)
        self.model = model
        self.chunker = MarkdownChunker(max_chunk_size, min_chunk_size)
        self.verbose = verbose

    def _log(self, msg: str):
        if self.verbose:
            print(msg, file=sys.stderr)

    def fix_chunk(self, chunk: str, chunk_index: int, total_chunks: int) -> str:
        """å˜ä¸€ãƒãƒ£ãƒ³ã‚¯ã‚’ä¿®å¾©"""
        try:
            self._log(
                f"ğŸ”§ ä¿®å¾©ä¸­ ({chunk_index + 1}/{total_chunks}) - {len(chunk)} æ–‡å­—..."
            )
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": REPAIR_SYSTEM_PROMPT},
                    {"role": "user", "content": chunk},
                ],
                temperature=0,
            )
            fixed = response.choices[0].message.content.strip()
            usage = getattr(response, "usage", None)
            if usage:
                self._log(
                    f"  âœ… å…¥åŠ›: {usage.prompt_tokens}toks, å‡ºåŠ›: {usage.completion_tokens}toks"
                )
            return fixed
        except Exception as e:
            self._log(f"  âŒ ã‚¨ãƒ©ãƒ¼: {e}")
            return chunk

    def fix_text(self, markdown_text: str, delay: float = 1.0) -> str:
        """Markdownæ–‡å­—åˆ—ã‚’ä¿®å¾©ã—ã¦è¿”ã™"""
        chunks = self.chunker.split_markdown(markdown_text)
        fixed_chunks = []
        start_time = time.time()
        for i, chunk in enumerate(chunks):
            fixed_chunks.append(self.fix_chunk(chunk, i, len(chunks)))
            if i < len(chunks) - 1 and delay > 0:
                time.sleep(delay)
        fixed_markdown = "\n\n".join(fixed_chunks)
        self._log(f"âœ… å®Œäº†: {len(chunks)} ãƒãƒ£ãƒ³ã‚¯, {time.time() - start_time:.1f} ç§’")
        return fixed_markdown

    def fix_file(self, input_path: str, delay: float = 1.0) -> str:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¿®å¾©å¾ŒMarkdownã‚’è¿”ã™"""
        input_file = Path(input_path)
        if not input_file.exists():
            raise FileNotFoundError(f"å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {input_path}")
        self._log(f"ğŸ“– èª­ã¿è¾¼ã¿: {input_path}")
        markdown_text = input_file.read_text(encoding="utf-8")
        return self.fix_text(markdown_text, delay=delay)


def parse_args():
    p = argparse.ArgumentParser(
        description="PDFç­‰ã‹ã‚‰å¤‰æ›ã•ã‚ŒãŸMarkdownã‚’æ§‹é€ ä¿®å¾©ã—ã¦å‡ºåŠ›ã™ã‚‹CLI"
    )
    p.add_argument(
        "path", help="å…¥åŠ›Markdownãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã€‚'-' ã‚’æŒ‡å®šã™ã‚‹ã¨STDINã‹ã‚‰èª­ã¿è¾¼ã¿"
    )
    p.add_argument(
        "--api-key", help="OpenAI APIã‚­ãƒ¼ï¼ˆæœªæŒ‡å®šæ™‚ã¯ç’°å¢ƒå¤‰æ•° OPENAI_API_KEY ã‚’ä½¿ç”¨ï¼‰"
    )
    p.add_argument(
        "--model", default="gpt-4.1-mini", help="ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«ï¼ˆæ—¢å®š: gpt-4.1-miniï¼‰"
    )
    p.add_argument(
        "--max-chunk-size", type=int, default=5000, help="ãƒãƒ£ãƒ³ã‚¯æœ€å¤§æ–‡å­—æ•°"
    )
    p.add_argument(
        "--min-chunk-size", type=int, default=1000, help="ãƒãƒ£ãƒ³ã‚¯æœ€å°æ–‡å­—æ•°"
    )
    p.add_argument(
        "--delay",
        type=float,
        default=0,
        help="APIå‘¼ã³å‡ºã—é–“ã®å¾…æ©Ÿç§’ï¼ˆãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–ï¼‰",
    )
    p.add_argument(
        "--output", "-o", help="å‡ºåŠ›å…ˆãƒ‘ã‚¹ã€‚æœªæŒ‡å®šãªã‚‰STDOUTã€‚'-'ã§STDOUTã‚’æ˜ç¤º"
    )
    p.add_argument(
        "--verbose", action="store_true", help="é€²æ—ãƒ­ã‚°ã‚’è¡¨ç¤ºï¼ˆSTDERRã«å‡ºåŠ›ï¼‰"
    )
    return p.parse_args()


def main():
    args = parse_args()

    # å…¥åŠ›èª­ã¿è¾¼ã¿
    if args.path == "-":
        src_text = sys.stdin.read()
        use_stdin = True
    else:
        use_stdin = False

    fixer = MarkdownFixer(
        api_key=args.api_key,
        model=args.model,
        max_chunk_size=args.max_chunk_size,
        min_chunk_size=args.min_chunk_size,
        verbose=args.verbose,
    )

    if use_stdin:
        fixed_md = fixer.fix_text(src_text, delay=args.delay)
    else:
        fixed_md = fixer.fix_file(args.path, delay=args.delay)

    # å‡ºåŠ›
    if args.output and args.output != "-":
        Path(args.output).write_text(fixed_md, encoding="utf-8")
    else:
        # STDOUTã¸
        sys.stdout.write(fixed_md)


if __name__ == "__main__":
    main()
