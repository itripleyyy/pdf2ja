import os
import time
from pathlib import Path
from typing import List
from openai import OpenAI

# ä¿®å¾©ç”¨ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
REPAIR_SYSTEM_PROMPT = """ã‚ãªãŸã¯ã€PDFãªã©ã‹ã‚‰è‡ªå‹•å¤‰æ›ã•ã‚ŒãŸMarkdownæ–‡æ›¸ã‚’ä¿®å¾©ã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚
å…¥åŠ›ã•ã‚Œã‚‹Markdownã«ã¯ã€è«–æ–‡ã‚„æŠ€è¡“æ›¸ã«å«ã¾ã‚Œã‚‹å†…å®¹ï¼ˆã‚³ãƒ¼ãƒ‰ã€æ•°å¼ã€å›³ã€è¡¨ã€æ®µè½ãªã©ï¼‰ãŒå«ã¾ã‚Œã¾ã™ã€‚
ä»¥ä¸‹ã®æŒ‡ç¤ºã«å¾“ã„ã€Markdownã‚’å†æ§‹ç¯‰ã—ã¦ãã ã•ã„ã€‚

- ã‚³ãƒ¼ãƒ‰ï¼ˆãƒ—ãƒ­ã‚°ãƒ©ãƒ ã€æ“¬ä¼¼ã‚³ãƒ¼ãƒ‰ã€ã‚³ãƒãƒ³ãƒ‰å‡ºåŠ›ï¼‰ã¯é©åˆ‡ãª```ãƒ–ãƒ­ãƒƒã‚¯ã§å›²ã£ã¦ãã ã•ã„ã€‚å¯èƒ½ã§ã‚ã‚Œã°è¨€èªã‚’æŒ‡å®šã—ã¦ãã ã•ã„ï¼ˆä¾‹ï¼š```pythonã€```bashã€```textï¼‰ã€‚
- æ•°å¼ã‚„æ•°å€¤è¡¨ç¾ï¼ˆä¾‹ï¼š$x^2 + y^2 = r^2$ã€\begin{equation}ãªã©ï¼‰ã¯Markdownã¾ãŸã¯LaTeXå½¢å¼ã§æ­£ã—ãè¡¨ç¤ºã•ã‚Œã‚‹ã‚ˆã†ä¿å…¨ã—ã¦ãã ã•ã„ã€‚
- èª¤ã£ã¦è¦‹å‡ºã—ï¼ˆä¾‹ï¼š`# ã‚³ãƒ¡ãƒ³ãƒˆ`ï¼‰ã¨ã—ã¦å‡¦ç†ã•ã‚ŒãŸè¡Œã¯ã€è¦‹å‡ºã—ã§ã¯ãªãæœ¬æ–‡ã‚„ã‚³ãƒ¡ãƒ³ãƒˆã¨ã—ã¦æ‰±ã£ã¦ãã ã•ã„ã€‚
- ä¸é©åˆ‡ãªæ”¹è¡Œã‚„ç®‡æ¡æ›¸ãã®å´©ã‚Œã€ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆã®èª¤ã‚Šã‚’ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚
- å›³ã‚„è¡¨ï¼ˆãƒ†ãƒ¼ãƒ–ãƒ«ï¼‰ã¨æ€ã‚ã‚Œã‚‹éƒ¨åˆ†ã¯Markdownè¨˜æ³•ã§è¡¨ç¾ã§ãã‚‹ã‚ˆã†ã«æ•´å½¢ã—ã¦ãã ã•ã„ã€‚
- ç”»åƒãƒªãƒ³ã‚¯ï¼ˆ![]()è¨˜æ³•ï¼‰ã¯ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯å†…ã«å«ã‚ãªã„ã§ãã ã•ã„ã€‚ç”»åƒãƒªãƒ³ã‚¯ã®å†…å®¹ï¼ˆãƒ‘ã‚¹ã‚„URLï¼‰ã¯ä¸€åˆ‡å¤‰æ›´ã—ãªã„ã§ãã ã•ã„ã€‚
- å†…å®¹ã‚’è¦ç´„ãƒ»æ”¹å¤‰ã—ãªã„ã§ãã ã•ã„ã€‚**æ§‹é€ ã®ä¿®æ­£ã®ã¿ã«ç•™ã‚ã¦ãã ã•ã„ã€‚**

å‡ºåŠ›ã¯**Markdownå½¢å¼ã®ã¿**ã§è¿”ã—ã¦ãã ã•ã„ã€‚èª¬æ˜ã‚„è£œè¶³ã‚³ãƒ¡ãƒ³ãƒˆã¯ä¸è¦ã§ã™ã€‚"""


class MarkdownFixer:
    """Markdownæ§‹æ–‡ä¿®å¾©ã‚’æ‹…å½“ã™ã‚‹ã‚¯ãƒ©ã‚¹"""

    def __init__(
        self,
        api_key: str = None,
        model: str = "gpt-4o-mini",
        max_chunk_size: int = 5000,
        min_chunk_size: int = 500,
    ):
        """
        Markdownä¿®å¾©ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–

        Args:
            api_key: OpenAI APIã‚­ãƒ¼ï¼ˆNoneã®å ´åˆã¯ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ï¼‰
            model: ä½¿ç”¨ã™ã‚‹OpenAIãƒ¢ãƒ‡ãƒ«
            max_chunk_size: ãƒãƒ£ãƒ³ã‚¯æœ€å¤§æ–‡å­—æ•°
            min_chunk_size: ãƒãƒ£ãƒ³ã‚¯æœ€å°æ–‡å­—æ•°
        """
        self.api_key = api_key or os.environ.get("OPENAI_API_KEY")
        if not self.api_key:
            raise ValueError(
                "OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ç’°å¢ƒå¤‰æ•°OPENAI_API_KEYã¾ãŸã¯å¼•æ•°ã§æŒ‡å®šã—ã¦ãã ã•ã„ã€‚"
            )

        self.client = OpenAI(api_key=self.api_key)
        self.model = model

        # ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ã‚’æ‹…å½“ã™ã‚‹ã‚¯ãƒ©ã‚¹
        self.chunker = MarkdownChunker(max_chunk_size, min_chunk_size)

    def fix_chunk(self, chunk: str, chunk_index: int, total_chunks: int) -> str:
        """å˜ä¸€ãƒãƒ£ãƒ³ã‚¯ã‚’ä¿®å¾©"""
        try:
            print(f"ğŸ”§ ä¿®å¾©ä¸­ ({chunk_index + 1}/{total_chunks}) - {len(chunk)}æ–‡å­—...")

            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": REPAIR_SYSTEM_PROMPT},
                    {"role": "user", "content": chunk},
                ],
                temperature=0,
                max_tokens=None,  # gpt-4o-miniã¯è‡ªå‹•ã§æœ€å¤§ã¾ã§ä½¿ç”¨
            )

            fixed = response.choices[0].message.content.strip()

            # APIã®ä½¿ç”¨é‡æƒ…å ±ã‚’è¡¨ç¤ºï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
            usage = response.usage
            print(
                f"  âœ… å®Œäº† - å…¥åŠ›: {usage.prompt_tokens}tokens, å‡ºåŠ›: {usage.completion_tokens}tokens"
            )

            return fixed

        except Exception as e:
            print(f"  âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}")
            # ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯å…ƒã®ãƒãƒ£ãƒ³ã‚¯ã‚’è¿”ã™ï¼ˆä¿®å¾©å¤±æ•—ã§ã‚‚å‡¦ç†ç¶šè¡Œï¼‰
            return chunk

    def fix_file(
        self, input_path: str, output_path: str = None, delay: float = 1.0
    ) -> str:
        """
        Markdownãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿®å¾©

        Args:
            input_path: å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            output_path: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆNoneã®å ´åˆã¯è‡ªå‹•ç”Ÿæˆï¼‰
            delay: APIå‘¼ã³å‡ºã—é–“ã®å¾…æ©Ÿæ™‚é–“ï¼ˆç§’ï¼‰

        Returns:
            ä¿®å¾©å¾Œã®Markdownãƒ†ã‚­ã‚¹ãƒˆ
        """
        input_file = Path(input_path)
        if not input_file.exists():
            raise FileNotFoundError(f"å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {input_path}")

        # å‡ºåŠ›ãƒ‘ã‚¹ã®è‡ªå‹•ç”Ÿæˆ
        if output_path is None:
            output_path = (
                input_file.parent / f"{input_file.stem}_fixed{input_file.suffix}"
            )

        print(f"ğŸ“– ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿: {input_path}")
        markdown_text = input_file.read_text(encoding="utf-8")
        print(f"ğŸ“Š ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {len(markdown_text):,}æ–‡å­—")

        # ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ï¼ˆMarkdownChunkerã«å§”è­²ï¼‰
        chunks = self.chunker.split_markdown(markdown_text)

        if len(chunks) == 1:
            print("ğŸ“„ åˆ†å‰²ä¸è¦ï¼ˆå˜ä¸€ãƒãƒ£ãƒ³ã‚¯ï¼‰")

        # å„ãƒãƒ£ãƒ³ã‚¯ã‚’ä¿®å¾©
        fixed_chunks = []
        start_time = time.time()

        for i, chunk in enumerate(chunks):
            fixed_chunk = self.fix_chunk(chunk, i, len(chunks))
            fixed_chunks.append(fixed_chunk)

            # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–ï¼ˆæœ€å¾Œã®ãƒãƒ£ãƒ³ã‚¯ä»¥å¤–ã§å¾…æ©Ÿï¼‰
            if i < len(chunks) - 1 and delay > 0:
                time.sleep(delay)

        # ä¿®å¾©çµæœã‚’çµåˆ
        fixed_markdown = "\n\n".join(fixed_chunks)

        # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        output_file = Path(output_path)
        output_file.write_text(fixed_markdown, encoding="utf-8")

        # çµæœã‚µãƒãƒªãƒ¼
        elapsed_time = time.time() - start_time
        print("\n" + "=" * 50)
        print("ğŸ‰ ä¿®å¾©å®Œäº†!")
        print(f"ğŸ“ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {output_path}")
        print(f"ğŸ“Š ãƒãƒ£ãƒ³ã‚¯æ•°: {len(chunks)}")
        print(f"â±ï¸  æ‰€è¦æ™‚é–“: {elapsed_time:.1f}ç§’")
        print(f"ğŸ“ˆ ä¿®å¾©å¾Œã‚µã‚¤ã‚º: {len(fixed_markdown):,}æ–‡å­—")
        print("=" * 50)

        return fixed_markdown
